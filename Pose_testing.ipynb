{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a53c9ba-ff7d-4a11-84c8-7a1a4985e27f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting torchvision==0.14.1\n",
      "  Downloading torchvision-0.14.1-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torchvision==0.14.1) (9.4.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torchvision==0.14.1) (1.21.6)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torchvision==0.14.1) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torchvision==0.14.1) (4.5.0)\n",
      "Collecting torch==1.13.1\n",
      "  Downloading torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m983.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision==0.14.1) (65.6.3)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision==0.14.1) (0.38.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision==0.14.1) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision==0.14.1) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision==0.14.1) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision==0.14.1) (3.4)\n",
      "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.5.1\n",
      "    Uninstalling torch-1.5.1:\n",
      "      Successfully uninstalled torch-1.5.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.6.1\n",
      "    Uninstalling torchvision-0.6.1:\n",
      "      Successfully uninstalled torchvision-0.6.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torcheia 1.0.0 requires torch==1.5.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1 torchvision-0.14.1\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting tensorboard==2.11.1\n",
      "  Downloading tensorboard-2.11.1-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.11.1) (2.2.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.11.1) (65.6.3)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.11.1) (0.38.4)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.11.1) (1.21.6)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.2/178.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.9.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.11.1) (3.20.3)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.54.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard==2.11.1) (2.28.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.11.1) (1.16.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.11.1) (4.7.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard==2.11.1) (4.11.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.11.1) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.11.1) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.11.1) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard==2.11.1) (2.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard==2.11.1) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.11.1) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.11.1) (4.5.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.11.1) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'tensorboard' candidate (version 2.11.1 at https://files.pythonhosted.org/packages/70/6a/95cedf185fa0063d4a6d8251b5601071e58a4ef15202dbf93773f13c7383/tensorboard-2.11.1-py3-none-any.whl (from https://pypi.org/simple/tensorboard/) (requires-python:>=3.7))\n",
      "Reason for being yanked: This release includes a bug in which the TB Uploader authentication flow using the console is broken.\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tensorboard-plugin-wit, tensorboard-data-server, pyasn1-modules, oauthlib, grpcio, cachetools, absl-py, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard\n",
      "Successfully installed absl-py-1.4.0 cachetools-5.3.0 google-auth-2.17.3 google-auth-oauthlib-0.4.6 grpcio-1.54.0 markdown-3.4.3 oauthlib-3.2.2 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.11.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting torch-summary\n",
      "  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: torch-summary\n",
      "Successfully installed torch-summary-1.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torchvision==0.14.1\n",
    "!pip3 install tensorboard==2.11.1\n",
    "!pip3 install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1952f608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio \n",
    "import glob\n",
    "import datetime\n",
    "import time\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from data.dataloader import create_dataloader\n",
    "from models.pose_transfer_model import PoseTransferModel\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53e022f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# configurations\n",
    "# -----------------------------------------------------------------------------\n",
    "root_path = '/home/ec2-user/SageMaker'\n",
    "dataset_name = 'deepfashion'\n",
    "\n",
    "dataset_root = f'{root_path}/datasets/{dataset_name}'\n",
    "img_pairs_train = f'{dataset_root}/train_img_pairs1.csv'\n",
    "img_pairs_test = f'{dataset_root}/test_img_pairs1.csv'\n",
    "\n",
    "pose_maps_dir_train = f'{dataset_root}/train_pose_maps'\n",
    "pose_maps_dir_test = f'{dataset_root}/test_pose_maps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33a7aafb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpu_ids = [0]\n",
    "\n",
    "batch_size_train = 8\n",
    "batch_size_test = 8\n",
    "n_epoch = 1\n",
    "out_freq = 500\n",
    "\n",
    "ckpt_id = None\n",
    "ckpt_dir = None\n",
    "\n",
    "run_info = ''\n",
    "out_path = f'{root_path}/output/{dataset_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a030694-8185-492f-986a-6a36e9f803f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: GPU0 -> Tesla T4\n",
      "[INFO] Network netG initialized\n",
      "[INFO] Network netD initialized\n",
      "--------------------------------------------------------------------------------\n",
      "[INFO] Total parameters of network netG: 126.40M\n",
      "[INFO] Total parameters of network netD: 2.77M\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# create timestamp and infostamp\n",
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "infostamp = f'_{run_info.strip()}' if run_info.strip() else ''\n",
    "\n",
    "# create tensorboard logger\n",
    "logger = SummaryWriter(f'{out_path}/runs/{timestamp}{infostamp}')\n",
    "\n",
    "# create transforms\n",
    "img_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "map_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# create dataloaders\n",
    "train_dataloader = create_dataloader(dataset_root, img_pairs_train, pose_maps_dir_train,\n",
    "                                     img_transform, map_transform,\n",
    "                                     batch_size=batch_size_train, shuffle=True)\n",
    "test_dataloader = create_dataloader(dataset_root, img_pairs_test, pose_maps_dir_test,\n",
    "                                    img_transform, map_transform,\n",
    "                                    batch_size=batch_size_test, shuffle=False)\n",
    "\n",
    "# create fixed batch for testing\n",
    "fixed_test_batch = next(iter(test_dataloader))\n",
    "\n",
    "# create model\n",
    "model = PoseTransferModel(gpuids=gpu_ids)\n",
    "model.print_networks(verbose=False)\n",
    "\n",
    "# load pretrained weights into model\n",
    "if ckpt_id and ckpt_dir:\n",
    "    model.load_networks(ckpt_dir, ckpt_id, verbose=True)\n",
    "\n",
    "# train model\n",
    "n_batch = len(train_dataloader)\n",
    "w_batch = len(str(n_batch))\n",
    "w_epoch = len(str(n_epoch))\n",
    "n_iters = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49dfc572-1bfa-49a7-8201-6df0b3fff795",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:    1/4670 | LossG: 154.4315 | LossD:  1.9043 | Time: 1.82 sec |\n",
      "[INFO] Network netG weights saved to /home/ec2-user/SageMaker/output/deepfashion/ckpt/2023-05-02-01-08-16/netG_0.pth\n",
      "[INFO] Network netD weights saved to /home/ec2-user/SageMaker/output/deepfashion/ckpt/2023-05-02-01-08-16/netD_0.pth\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:    2/4670 | LossG: 148.3748 | LossD: 112.0056 | Time: 1.82 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:    3/4670 | LossG: 12.9942 | LossD: 156.3380 | Time: 1.83 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:    4/4670 | LossG: 12.3169 | LossD:  5.2008 | Time: 1.82 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:    5/4670 | LossG:  7.6475 | LossD:  4.5249 | Time: 1.83 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:    6/4670 | LossG:  7.5096 | LossD:  0.8337 | Time: 1.83 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:    7/4670 | LossG:  6.8286 | LossD:  0.7077 | Time: 1.83 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:    8/4670 | LossG:  8.1094 | LossD:  0.3366 | Time: 1.84 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:    9/4670 | LossG:  6.1661 | LossD:  0.3424 | Time: 1.84 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   10/4670 | LossG:  6.6834 | LossD:  0.2883 | Time: 1.84 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   11/4670 | LossG:  6.1114 | LossD:  0.2638 | Time: 1.83 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   12/4670 | LossG:  6.4177 | LossD:  0.2535 | Time: 1.85 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   13/4670 | LossG:  6.0434 | LossD:  0.2361 | Time: 1.85 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   14/4670 | LossG:  7.0575 | LossD:  0.2252 | Time: 1.85 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   15/4670 | LossG:  5.9956 | LossD:  0.2531 | Time: 1.85 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   16/4670 | LossG:  6.0266 | LossD:  0.2667 | Time: 1.86 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   17/4670 | LossG:  6.0097 | LossD:  0.2264 | Time: 1.86 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   18/4670 | LossG:  6.0599 | LossD:  0.2402 | Time: 1.86 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   19/4670 | LossG:  6.0141 | LossD:  0.2365 | Time: 1.86 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   20/4670 | LossG:  5.9268 | LossD:  0.2135 | Time: 1.87 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   21/4670 | LossG:  5.9578 | LossD:  0.2600 | Time: 1.87 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   22/4670 | LossG:  6.4902 | LossD:  0.2327 | Time: 1.88 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   23/4670 | LossG:  5.7010 | LossD:  0.2433 | Time: 1.88 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   24/4670 | LossG:  5.2953 | LossD:  0.2267 | Time: 1.88 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   25/4670 | LossG:  5.9818 | LossD:  0.1995 | Time: 1.88 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   26/4670 | LossG:  5.7463 | LossD:  0.2203 | Time: 1.88 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   27/4670 | LossG:  5.6172 | LossD:  0.2396 | Time: 1.89 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   28/4670 | LossG:  5.0524 | LossD:  0.2332 | Time: 1.89 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   29/4670 | LossG:  5.5735 | LossD:  0.2292 | Time: 1.89 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   30/4670 | LossG:  5.2698 | LossD:  0.2389 | Time: 1.90 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   31/4670 | LossG:  5.4608 | LossD:  0.2475 | Time: 1.90 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   32/4670 | LossG:  5.1803 | LossD:  0.2554 | Time: 1.89 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   33/4670 | LossG:  5.2692 | LossD:  0.2389 | Time: 1.90 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   34/4670 | LossG:  5.3847 | LossD:  0.2109 | Time: 1.90 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   35/4670 | LossG:  5.7463 | LossD:  0.2070 | Time: 1.90 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   36/4670 | LossG:  6.2253 | LossD:  0.2234 | Time: 1.91 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   37/4670 | LossG:  5.6665 | LossD:  0.2156 | Time: 1.91 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   38/4670 | LossG:  5.6447 | LossD:  0.2191 | Time: 1.92 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   39/4670 | LossG:  5.9876 | LossD:  0.2256 | Time: 1.91 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   40/4670 | LossG:  5.3163 | LossD:  0.2404 | Time: 1.92 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   41/4670 | LossG:  5.8015 | LossD:  0.2177 | Time: 1.92 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   42/4670 | LossG:  5.6872 | LossD:  0.1912 | Time: 1.92 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   43/4670 | LossG:  7.1451 | LossD:  0.1889 | Time: 1.92 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   44/4670 | LossG:  5.3941 | LossD:  0.1918 | Time: 1.93 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   45/4670 | LossG:  5.2744 | LossD:  0.2188 | Time: 1.93 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   46/4670 | LossG:  5.6765 | LossD:  0.2175 | Time: 1.93 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   47/4670 | LossG:  5.3136 | LossD:  0.2001 | Time: 1.93 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   48/4670 | LossG:  5.7241 | LossD:  0.2166 | Time: 1.93 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   49/4670 | LossG:  6.0261 | LossD:  0.1997 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   50/4670 | LossG:  5.9743 | LossD:  0.2036 | Time: 1.93 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   51/4670 | LossG:  6.0886 | LossD:  0.1870 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   52/4670 | LossG:  5.6883 | LossD:  0.1836 | Time: 1.93 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   53/4670 | LossG:  5.5561 | LossD:  0.2127 | Time: 1.93 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   54/4670 | LossG:  5.8363 | LossD:  0.2309 | Time: 1.93 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   55/4670 | LossG:  5.4813 | LossD:  0.2384 | Time: 1.93 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   56/4670 | LossG:  5.7973 | LossD:  0.2096 | Time: 1.93 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   57/4670 | LossG:  6.5034 | LossD:  0.1730 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   58/4670 | LossG:  5.1261 | LossD:  0.1952 | Time: 1.93 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   59/4670 | LossG:  4.9945 | LossD:  0.2227 | Time: 1.93 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   60/4670 | LossG:  5.6193 | LossD:  0.2898 | Time: 1.93 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   61/4670 | LossG:  5.4026 | LossD:  0.4206 | Time: 1.93 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   62/4670 | LossG:  5.4350 | LossD:  0.3850 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   63/4670 | LossG:  5.4510 | LossD:  0.2782 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   64/4670 | LossG:  5.2379 | LossD:  0.2131 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   65/4670 | LossG:  5.5118 | LossD:  0.2056 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   66/4670 | LossG:  5.3960 | LossD:  0.2182 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   67/4670 | LossG:  5.9602 | LossD:  0.1936 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   68/4670 | LossG:  5.6951 | LossD:  0.2435 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   69/4670 | LossG:  5.7945 | LossD:  0.1967 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   70/4670 | LossG:  5.3027 | LossD:  0.2245 | Time: 1.93 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   71/4670 | LossG:  5.4428 | LossD:  0.1936 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   72/4670 | LossG:  5.5089 | LossD:  0.1718 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   73/4670 | LossG:  5.5001 | LossD:  0.2715 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   74/4670 | LossG:  5.4521 | LossD:  0.1724 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   75/4670 | LossG:  6.2169 | LossD:  0.1735 | Time: 1.95 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   76/4670 | LossG:  5.4804 | LossD:  0.2268 | Time: 1.95 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   77/4670 | LossG:  6.2638 | LossD:  0.2740 | Time: 1.95 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   78/4670 | LossG:  5.5625 | LossD:  0.3508 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   79/4670 | LossG:  5.3262 | LossD:  0.3205 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   80/4670 | LossG:  4.9838 | LossD:  0.2462 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   81/4670 | LossG:  5.9870 | LossD:  0.2319 | Time: 1.95 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   82/4670 | LossG:  5.2436 | LossD:  0.2098 | Time: 1.95 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   83/4670 | LossG:  5.6221 | LossD:  0.2265 | Time: 1.95 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   84/4670 | LossG:  6.0447 | LossD:  0.2019 | Time: 1.95 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   85/4670 | LossG:  5.4966 | LossD:  0.2260 | Time: 1.94 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   86/4670 | LossG:  5.9431 | LossD:  0.2241 | Time: 1.95 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   87/4670 | LossG:  5.8622 | LossD:  0.1955 | Time: 1.95 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   88/4670 | LossG:  5.5481 | LossD:  0.2067 | Time: 1.95 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   89/4670 | LossG:  5.3423 | LossD:  0.2771 | Time: 1.95 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   90/4670 | LossG:  4.6077 | LossD:  0.2276 | Time: 1.96 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   91/4670 | LossG:  5.8983 | LossD:  0.1899 | Time: 1.96 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   92/4670 | LossG:  5.5947 | LossD:  0.2240 | Time: 1.96 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   93/4670 | LossG:  5.7398 | LossD:  0.1977 | Time: 1.95 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   94/4670 | LossG:  4.9138 | LossD:  0.1846 | Time: 1.96 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   95/4670 | LossG:  5.3092 | LossD:  0.2328 | Time: 1.96 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   96/4670 | LossG:  5.8696 | LossD:  0.3050 | Time: 1.95 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   97/4670 | LossG:  5.4361 | LossD:  0.2415 | Time: 1.95 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   98/4670 | LossG:  5.0896 | LossD:  0.2894 | Time: 1.95 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:   99/4670 | LossG:  5.3813 | LossD:  0.3890 | Time: 1.95 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:  100/4670 | LossG:  5.3177 | LossD:  0.5471 | Time: 1.95 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:  101/4670 | LossG:  5.4289 | LossD:  0.4705 | Time: 1.96 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:  102/4670 | LossG:  5.1653 | LossD:  0.3254 | Time: 1.96 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:  103/4670 | LossG:  5.7719 | LossD:  0.2244 | Time: 1.96 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:  104/4670 | LossG:  4.6016 | LossD:  0.2626 | Time: 1.96 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:  105/4670 | LossG:  5.4754 | LossD:  0.2773 | Time: 1.96 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:  106/4670 | LossG:  4.9158 | LossD:  0.2771 | Time: 1.96 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:  107/4670 | LossG:  5.4842 | LossD:  0.1789 | Time: 1.96 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:  108/4670 | LossG:  4.8598 | LossD:  0.1851 | Time: 1.96 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:  109/4670 | LossG:  5.6004 | LossD:  0.1945 | Time: 1.96 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n",
      "[TRAIN] Epoch: 1/1 | Batch:  110/4670 | LossG:  5.5952 | LossD:  0.2073 | Time: 1.96 sec |\n",
      "torch.Size([8, 3, 256, 256])\n",
      "torch.Size([8, 36, 256, 256])\n",
      "torch.Size([8, 6, 256, 256])\n",
      "y shape:  torch.Size([8, 3, 256, 256])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14604/977731908.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtime_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lossG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/pose-transfer-apts/models/base_model.py\u001b[0m in \u001b[0;36moptimize_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/pose-transfer-apts/models/pose_transfer_model.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_requires_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'netD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizerG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizerG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/pose-transfer-apts/models/pose_transfer_model.py\u001b[0m in \u001b[0;36mbackward_G\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlossG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlossG_L1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlossG_GAN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlossG_PER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlossG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         )\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    for batch, data in enumerate(train_dataloader):\n",
    "        time_0 = time.time()\n",
    "        model.set_inputs(data)\n",
    "        model.optimize_parameters()\n",
    "        losses = model.get_losses()\n",
    "        loss_G = losses['lossG']\n",
    "        loss_D = losses['lossD']\n",
    "        time_1 = time.time()\n",
    "        print(f'[TRAIN] Epoch: {epoch+1:{w_epoch}d}/{n_epoch} | Batch: {batch+1:{w_batch}d}/{n_batch} |',\n",
    "              f'LossG: {loss_G:7.4f} | LossD: {loss_D:7.4f} | Time: {round(time_1-time_0, 2):.2f} sec |')\n",
    "        \n",
    "        if (n_iters % out_freq == 0) or (batch+1 == n_batch and epoch+1 == n_epoch):\n",
    "            model.save_networks(f'{out_path}/ckpt/{timestamp}{infostamp}', n_iters, verbose=True)\n",
    "            for loss_name, loss in losses.items():\n",
    "                loss_group = 'LossG' if loss_name.startswith('lossG') else 'LossD'\n",
    "                logger.add_scalar(f'{loss_group}/{loss_name}', loss, n_iters)\n",
    "            model.set_inputs(fixed_test_batch)\n",
    "            visuals = model.compute_visuals()\n",
    "            logger.add_image(f'Iteration_{n_iters}', visuals, n_iters)\n",
    "        \n",
    "        n_iters += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb86ced-b7c3-4774-a498-97f96ebe6127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fe35ddd-168c-4865-ac88-a38b5e7cde4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1a9189-64c7-4625-b748-4fb2c685eccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551ccd2-c648-4ecf-a7f8-b12e970fbe93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ndf = pd.read_csv(img_pairs_train)\n",
    "# ndf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c52fd79-87b2-49c8-b83f-73e0a890f9ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'img_seg/WOMEN/Sweaters/id_00005106/07_1_front.png' in ndf['imgB_seg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "925c03a2-c29a-4aff-9a3e-0075814122d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ec2-user/SageMaker/datasets/deepfashion/img_seg/WOMEN/Sweaters/id_00005106/07_1_front.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14604/3516097312.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/ec2-user/SageMaker/datasets/deepfashion/img_seg/WOMEN/Sweaters/id_00005106/07_1_front.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ec2-user/SageMaker/datasets/deepfashion/img_seg/WOMEN/Sweaters/id_00005106/07_1_front.png'"
     ]
    }
   ],
   "source": [
    "# Image.open('/home/ec2-user/SageMaker/datasets/deepfashion/img_seg/WOMEN/Sweaters/id_00005106/07_1_front.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6b685fe-2d7c-4444-a087-75a9f190c7b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for im in ndf['imgB_seg']:\n",
    "#     print(im)\n",
    "#     Image.open(dataset_root +'/'+ im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d37d17b-71a2-4ee9-bdab-d79f3aae448c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
